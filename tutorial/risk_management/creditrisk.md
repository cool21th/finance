[jalajthanaki](https://github.com/jalajthanaki/Awesome_Machine_Learning_Solutions) 의 솔루션(번역자 박진수님)을 참고하였습니다.


신용위험도 예측을 통해 고객이 채무 불이행 여부를 예측하는 모델을 만드는 튜토리얼입니다.
성능향상을 위해 outlier detection, feature transformation, ensemble 알고리즘등을 사용할 것입니다.

### 개요

은행, NBFS, 채권은행 등과 같은 금융기관이 여신을 위해 신용을 부여할 만한 사람인지를 예측할 수 있는 알고리즘을 만드는 것에서 부터 시작합니다
금융기관 입장에서 중요한 것은 돈을 빌려줘도 잘 갚을 사람인지 여부를 잘 판단해야 적은 감수해야 할 위험이 낮아질 것입니다. 

해당 금융기관에서는 채무자가 앞으로 돈을 충분히 갚을 수 있을지 여부를 조사하게 됩니다. 
조사 대상은 크게 보면 현재 수입과 지출, 고용 안정성, 기타 채무 상태, 연체여부, 사회 활동 가능기간, 부양가족 등이 될 것입니다.  

이번 모델링에서는 채무 불이행을 기준을 2년으로 튜토리얼을 진행할 것입니다. 
2 년이내 채무 불이행 가능성이 높은 고객이 모델 결과값이 높은 확률을 가지게 될 것입니다. 


### 데이터셋 이해

데이터 셋은 총 4개의 파일로 구성되어 있습니다

- cs-training.csv
- cs-test.csv
- DataDictionary.xls
- sampleEntry.csv

데이터 셋의 특성은 다음과 같습니다. 

1. SeriousDiqin2yrs:
> - 채무자가 지난 2년간 90일까지 기한경과 여부(연체여부)
> - 채무자가 지난 2년간 90일 이후에 대출금을 납부한 경우, 납부하지 않은 경우에도 'Yes' 값을 가집니다. 
> - target Label이 되는 값으로 훈련의 기준이 됩니다. 

2. RevolvingUtilizationOfUnsecuredLines:
> - 현재 대출 채무(loan debt) 및 부동산(real estate)을 제외한 채무자의 신용카드 한도를 나타냅니다. 
> - 계좌에 1000달러(A), 신용한도가 1000달러(B), 신용카드 사용 금액이 500 달러(C) 이면  필드 값은 (A+ B -C)/ A+B  = 0.75가 됩니다

3. Age:
> - 나이

4. NumberOfTime30-59DaysPastDueNotWorse:
> - 채무자가 뒤늦게라도 원리금을 지불했지만, 만기일로부터 30일이 지난 후 또는 만기일로부터 59일이 지나기 전에 지불한 횟수를 의미합니다. 

5. DebtRatio:
> - 부채비율을 의미합니다. 
> - 월 고정 부채가 200 달러(A), 평소 지출 500달러(B), 월 소득이 1000달러(c) 이면, A+B / C = 0.7 이 DebtRatio가 됩니다. 

6. MonthlyIncome:
> - 월간소득을 의미합니다.

7. NumberOfOpenCreditLinesAndLoans:
> - 자유 상환 대출 개수 및 채무자가 유지하는 신용카드 개수를 의미합니다.(신용카드와 기타 자유 대출을 동일시 합니다)

8. NumberOfTimes90DaysLate:
> - 채무자가 자신의 원리금을 지급한 날로부터 연체한 횟수를 나타냅니다.

9. NumberRealEstateLoansOrLines:
> - 채무자가 부동산 담보대출 또는 주택담보 대출 개수를 나타냅니다. 

10. NumberOfTime60-89DaysPastDueNotWorse:
> - 채무자가 늦게 원리금을 지불했지만 만기일로부터 60일 지난후 또는 89일 이 지나기 전에 지불한 횟수를 나타냅니다.

11. NumberOfDependents:
> - 채무자를 제외한 부양가족 수를 나타냅니다. 



### 데이터 분석

데이터 분석을 하기 앞서 기본적인 데이터 전처리를 수행할 것입니다. 
그리고 나서, EDA(Exploratory data analysis)를 통해 필요한 데이터 전처리를 수행하면서 분석할 것입니다., 

1. 기본적인 데이터 전처리

> 기본적인 데이터 전처리에서는 데이터 자체를 보면서 수행하기 보다는
> EDA에 앞서 불편한 부분들을 제거하는 과정입니다. 

> 제목이 없는 열에 제목을 추가하거나, 사용하지 않는 열은 삭제합니다. 
> 그리고, '-' 와 같은 칼럼명은 '-'를 제거한 형태로 진행할 것입니다. 

///////////////////////////////////////////////////////
///////////////////////////////////////////////////////
///////////////////////////////////////////////////////

2. 탐색적 데이터 분석(Exploratory Data Analysis, EDA)

> 훈련 데이터의 통계 특성을 찾는 과정입니다. 
> 간단한 알고리즘을 통해 데이터의 의미를 도출하거나, feature engineering을 통해 변수에 대한 인사이트를 얻을 수 있습니다. 

> - 통계속성 나열
> > pandas의 descirbe 함수를 통해 기본적인 정보를 얻을 수 있습니다. 
> > - count: 훈련 데이터 셋의 레코드 개수를 나타낸다
> > - mean: 각 칼럼의 평균을 보여줍니다
> > - std: 각 칼럼의 표준편차를 보여줍니다.
> > - min: 각 칼럼의 최소값를 보여줍니다.
> > - 25%: 각 칼럼의 25번째 백분위 수를 보여줍니다.
> > - 50%: 각 칼럼의 50번째 백분위 수를 보여줍니다.
> > - 75%: 각 칼럼의 75번째 백분위 수를 보여줍니다.
> > - max: 각 칼럼의 최대값을 보여줍니다.

> > 만약 중위수 만을 보고 싶으면 training_data[training_data.columns[1:]].median()
> > 평균 만을 보고 싶으면 training_data[training_data.columns[1:]].mean()
> > 기본적인 시각화는 seaborn을 통해 보여줄 수 있습니다. 

///////////////////////////////////////////////////////
///////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////

> > 데이터가 0인 레이블이 압도적으로 많은 것으로 보아 결과 값은 불균형합니다.


3. 결측값 찾기

> 데이터셋에서 결측값(Missing value)찾으려면 모든 데이터 특성을 검사해야 합니다. 
> Null 이 있는 데이터를 의미 있는 값으로 대체를 해야 하는데, 일반적으로 median 아니면 mean 값으로 대체 합니다. 

/////////////////////////////////////////////////////
/////////////////////////////////////////////////////
/////////////////////////////////////////////////////

4. 결측값 바꾸기

> 결측값을 대치하는 기술을 Imputation technique이라고 합니다. 
> 여러 가지 방법이 있을텐데, 기본적으로 하나씩 대체 해가면서, 모델의 성능 비교를 통해 결정합니다. 
> 1) 평균 2) 중위수 3) 레코드 삭제 4) Knn 을통한 이웃점으로 대체 5) 높은 빈출값으로 대체 등이 있습니다.

/////////////////////////////////////////////////////
/////////////////////////////////////////////////////
/////////////////////////////////////////////////////


5. 상관(correlation) 분석

> correlation 의 의미는 수량사이의 관계 또는 연관성을 의미합니다. 
> 특정 특성 값이 타겟 특성에 비례한다면 Positive association, 그 반대면 negative association을 의미합니다. 

///////////////////////////////////////////////////////
///////////////////////////////////////////////////////
///////////////////////////////////////////////////////


6. 이상점 검출

> 이상점 검출하는 방법과 처리하는 기법에 대해 이야기 하겠습니다. 
> 이상점을 검출하는 목적은 결과적으로 모델의 성능향상에 있습니다. 
> 데이터에 노이즈가 의도치 않게 생길 수 있거나, 정말 예외 처리를 해야 하는 데이터가 생길 수 있기 때문입니다. 
> 이상점 데이터를 모델에 반영을 한다면, 일반적으로 성능이 좋지 않은(overfitting) 결과를 가져올 확률이 아주 높습니다. 

> - 이상점 검출 기법
> > 이상점 검출 기법은 기본적으로 백분위수, 중위 절대 편차, 표준편차, 다수결 투표 기반 등 4가지가 있습니다.
> > 차례로 하나씩 도입해보겠습니다. 

> > - 백분위(percentile) 수 기반의 이상점 검출
> > - 중위수 절대 편차(median absolute deviation, MAD) 기반의 이상점 검출
> > - 표준편차(standard deviation) 기반의 이상점 검출
> > - 다수결 투표 기반의 이상점 검출
> > - 이상점의 시각화

//////////////////////////////////////////////////
코드
//////////////////////////////


7. 이상점 다루기

> 이상점을 찾기만 하고 데이터를 처리하는 단계가 없으면, EDA 과정이 큰 의미가 없게 됩니다. 
> 성능이 좋은 모델을 만들기 위해서는 이상점(outlier)를 잘 처리하는 과정을 이야기하도록 하겠습니다. 

> - 무담보 한도의 결제 이용금액
> > 데이터의 특성을 보면, 0.99999 이상인 값이 이상점으로 간주된다는 것을 알 수 있습니다. 
> > 그래서 0.99999를 기준으로 그보다 큰 값은 0.99999로 바꿔주면, outlier들을 정리할 수 있을 것입니다. 

> - 나이
> > 나이에 대한 데이터를 보면 0 이 있는데 잘못된 값인 것을 알 수 있을 것입니다. 
> > 이러한 경우에는 해당 row를 지우거나 0을 최소 나이(21)로 바꿔줘야 할 것입니다. 


> - 90일 연체회수
> > 90일이후에 미지급금을 지급한 회수로, 보통 17회에서 갑자기 96, 98로 뜨는것은 이상 데이터로 봐야 합니다. 

> - 담보대출 및 한도대출 수 대체
> > 90일 연체 회수와 동일하게 96, 98의 키값이 많이 발생하는 것을 알 수 있습니다. 해당 데이터에 대한 내용을 확인하는 것이 필요합니다. 

> - 부양가족 수 
> > 부양가족수 가 10이 넘는 경우가 보이는데, 일반적인 케이스가 아니라고 보입니다. 확인이 필요해 보입니다. 



### Feature Engineering

Feature Engineering은 예측모델을 개발하는데, 아주 중요한 단계입니다. 

쉽게 쓰이는 Ensemble모델인 Random Forest를 통해 기본적인 feature들의 중요도를 확인할 수 있습니다. 
물론 Random Forest 말고도 다른 알고리즘을 이용할 수 있습니다.
scikit-learn 라이브러리를 활용하면 쉽게 확인이 가능합니다. 
그리고 matplotlib를 활용하여 시각화를 한다면, 더욱 더 쉽게 확인할 수 있을 것입니다. 

### Machine Learning Algorithm 비교

여러 모델들을 동시에 훈련시켜 성능을 비교할 수 있습니다.

일반적으로 많이 사용하는 모델은 kNN(k-nearest neibors), Logistic regression, AdaBoost, Gradient Boost, Random Forest 등을 사용합니다. 

그리고, 모델들을 앙상블로 구성하여 성능 좋은 모델을 만들고 production으로 생성하여 지속적인 성능 관찰 및 업데이트를 수행합니다. 



