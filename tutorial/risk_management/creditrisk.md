[jalajthanaki](https://github.com/jalajthanaki/Awesome_Machine_Learning_Solutions) 의 솔루션(번역자 박진수님)을 참고하였습니다.


신용위험도 예측을 통해 고객이 채무 불이행 여부를 예측하는 모델을 만드는 튜토리얼입니다.
성능향상을 위해 outlier detection, feature transformation, ensemble 알고리즘등을 사용할 것입니다.

### 개요

은행, NBFS, 채권은행 등과 같은 금융기관이 여신을 위해 신용을 부여할 만한 사람인지를 예측할 수 있는 알고리즘을 만드는 것에서 부터 시작합니다
금융기관 입장에서 중요한 것은 돈을 빌려줘도 잘 갚을 사람인지 여부를 잘 판단해야 적은 감수해야 할 위험이 낮아질 것입니다. 

해당 금융기관에서는 채무자가 앞으로 돈을 충분히 갚을 수 있을지 여부를 조사하게 됩니다. 
조사 대상은 크게 보면 현재 수입과 지출, 고용 안정성, 기타 채무 상태, 연체여부, 사회 활동 가능기간, 부양가족 등이 될 것입니다.  

이번 모델링에서는 채무 불이행을 기준을 2년으로 튜토리얼을 진행할 것입니다. 
2 년이내 채무 불이행 가능성이 높은 고객이 모델 결과값이 높은 확률을 가지게 될 것입니다. 


### 데이터셋 이해

데이터 셋은 총 4개의 파일로 구성되어 있습니다

- cs-training.csv
- cs-test.csv
- DataDictionary.xls
- sampleEntry.csv

데이터 셋의 특성은 다음과 같습니다. 

1. SeriousDiqin2yrs:
> - 채무자가 지난 2년간 90일까지 기한경과 여부(연체여부)
> - 채무자가 지난 2년간 90일 이후에 대출금을 납부한 경우, 납부하지 않은 경우에도 'Yes' 값을 가집니다. 
> - target Label이 되는 값으로 훈련의 기준이 됩니다. 

2. RevolvingUtilizationOfUnsecuredLines:
> - 현재 대출 채무(loan debt) 및 부동산(real estate)을 제외한 채무자의 신용카드 한도를 나타냅니다. 
> - 계좌에 1000달러(A), 신용한도가 1000달러(B), 신용카드 사용 금액이 500 달러(C) 이면  필드 값은 (A+ B -C)/ A+B  = 0.75가 됩니다

3. Age:
> - 나이

4. NumberOfTime30-59DaysPastDueNotWorse:
> - 채무자가 뒤늦게라도 원리금을 지불했지만, 만기일로부터 30일이 지난 후 또는 만기일로부터 59일이 지나기 전에 지불한 횟수를 의미합니다. 

5. DebtRatio:
> - 부채비율을 의미합니다. 
> - 월 고정 부채가 200 달러(A), 평소 지출 500달러(B), 월 소득이 1000달러(c) 이면, A+B / C = 0.7 이 DebtRatio가 됩니다. 

6. MonthlyIncome:
> - 월간소득을 의미합니다.

7. NumberOfOpenCreditLinesAndLoans:
> - 자유 상환 대출 개수 및 채무자가 유지하는 신용카드 개수를 의미합니다.(신용카드와 기타 자유 대출을 동일시 합니다)

8. NumberOfTimes90DaysLate:
> - 채무자가 자신의 원리금을 지급한 날로부터 연체한 횟수를 나타냅니다.

9. NumberRealEstateLoansOrLines:
> - 채무자가 부동산 담보대출 또는 주택담보 대출 개수를 나타냅니다. 

10. NumberOfTime60-89DaysPastDueNotWorse:
> - 채무자가 늦게 원리금을 지불했지만 만기일로부터 60일 지난후 또는 89일 이 지나기 전에 지불한 횟수를 나타냅니다.

11. NumberOfDependents:
> - 채무자를 제외한 부양가족 수를 나타냅니다. 



### 데이터 분석

데이터 분석을 하기 앞서 기본적인 데이터 전처리를 수행할 것입니다. 
그리고 나서, EDA(Exploratory data analysis)를 통해 필요한 데이터 전처리를 수행하면서 분석할 것입니다., 

1. 기본적인 데이터 전처리

> 기본적인 데이터 전처리에서는 데이터 자체를 보면서 수행하기 보다는
> EDA에 앞서 불편한 부분들을 제거하는 과정입니다. 

> 제목이 없는 열에 제목을 추가하거나, 사용하지 않는 열은 삭제합니다. 
> 그리고, '-' 와 같은 칼럼명은 '-'를 제거한 형태로 진행할 것입니다. 

///////////////////////////////////////////////////////
///////////////////////////////////////////////////////
///////////////////////////////////////////////////////

2. 탐색적 데이터 분석(Exploratory Data Analysis, EDA)

> 훈련 데이터의 통계 특성을 찾는 과정입니다. 
> 간단한 알고리즘을 통해 데이터의 의미를 도출하거나, feature engineering을 통해 변수에 대한 인사이트를 얻을 수 있습니다. 

> - 통계속성 나열
> > pandas의 descirbe 함수를 통해 기본적인 정보를 얻을 수 있습니다. 
> > - count: 훈련 데이터 셋의 레코드 개수를 나타낸다
> > - mean: 각 칼럼의 평균을 보여줍니다
> > - std: 각 칼럼의 표준편차를 보여줍니다.
> > - min: 각 칼럼의 최소값를 보여줍니다.
> > - 25%: 각 칼럼의 25번째 백분위 수를 보여줍니다.
> > - 50%: 각 칼럼의 50번째 백분위 수를 보여줍니다.
> > - 75%: 각 칼럼의 75번째 백분위 수를 보여줍니다.
> > - max: 각 칼럼의 최대값을 보여줍니다.

> > 만약 중위수 만을 보고 싶으면 training_data[training_data.columns[1:]].median()
> > 평균 만을 보고 싶으면 training_data[training_data.columns[1:]].mean()
> > 기본적인 시각화는 seaborn을 통해 보여줄 수 있습니다. 

///////////////////////////////////////////////////////
///////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////

> > 데이터가 0인 레이블이 압도적으로 많은 것으로 보아 결과 값은 불균형합니다.


3. 결측값 찾기

> 데이터셋에서 결측값(Missing value)찾으려면 모든 데이터 특성을 검사해야 합니다. 
> Null 이 있는 데이터를 의미 있는 값으로 대체를 해야 하는데, 일반적으로 median 아니면 mean 값으로 대체 합니다. 

/////////////////////////////////////////////////////
/////////////////////////////////////////////////////
/////////////////////////////////////////////////////

4. 결측값 바꾸기

> 결측값을 대치하는 기술을 Imputation technique이라고 합니다. 
> 여러 가지 방법이 있을텐데, 기본적으로 하나씩 대체 해가면서, 모델의 성능 비교를 통해 결정합니다. 
> 1) 평균 2) 중위수 3) 레코드 삭제 4) Knn 을통한 이웃점으로 대체 5) 높은 빈출값으로 대체 등이 있습니다.

/////////////////////////////////////////////////////
/////////////////////////////////////////////////////
/////////////////////////////////////////////////////


5. 상관(correlation) 분석

> correlation 의 의미는 수량사이의 관계 또는 연관성을 의미합니다. 
> 특정 특성 값이 타겟 특성에 비례한다면 Positive association, 그 반대면 negative association을 의미합니다. 

///////////////////////////////////////////////////////
///////////////////////////////////////////////////////
///////////////////////////////////////////////////////


6. 이상점 검출

> 이상점 검출하는 방법과 처리하는 기법에 대해 이야기 하겠습니다. 
> 이상점을 검출하는 목적은 결과적으로 모델의 성능향상에 있습니다. 
> 데이터에 노이즈가 의도치 않게 생길 수 있거나, 정말 예외 처리를 해야 하는 데이터가 생길 수 있기 때문입니다. 
> 이상점 데이터를 모델에 반영을 한다면, 일반적으로 성능이 좋지 않은(overfitting) 결과를 가져올 확률이 아주 높습니다. 

> - 이상점 검출 기법
> > 이상점 검출 기법은 기본적으로 백분위수, 중위 절대 편차, 표준편차, 다수결 투표 기반 등 4가지가 있습니다.
> > 차례로 하나씩 도입해보겠습니다. 

> > - 백분위(percentile) 수 기반의 이상점 검출
> > > 
> > - 중위 절대 편차(median absolute deviation, MAD) 기반의 이상점 검출
> > - 표준편차(standard deviation) 기반의 이상점 검출
> > - 다수결 투표 기반의 이상점 검출
> > - 이상점의 시각화
